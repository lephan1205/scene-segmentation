{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Where to get the data\n",
    "PATH = os.path.join(os.getcwd(), \"data_dir\")\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_movies(path=PATH):\n",
    "    \"\"\"\n",
    "    Load .pkl movie files\n",
    "    \n",
    "    Argument:\n",
    "    ---------\n",
    "    path -- string representing files path\n",
    "    \"\"\"\n",
    "    filenames = glob.glob(os.path.join(PATH, \"tt*.pkl\"))\n",
    "    movies = []\n",
    "    for fn in filenames:\n",
    "        try:\n",
    "            with open(fn, 'rb') as fin:\n",
    "                movies.append(pickle.load(fin))\n",
    "        except EOFError:\n",
    "            break\n",
    "    return movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = fetch_movies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(data, train_size=60):\n",
    "    \"\"\"\n",
    "    Split data into train and test sets\n",
    "    \n",
    "    Argument:\n",
    "    --------\n",
    "    data -- a list of dictionaries each containing a movie information\n",
    "    train_size -- integer representing the number of movies used for training\n",
    "    \"\"\"\n",
    "    # For stable output across runs\n",
    "    np.random.seed(42)\n",
    "    # Shuffle indices\n",
    "    shuffled_indices = np.random.permutation(len(data))\n",
    "    train_indices = shuffled_indices[:train_size]\n",
    "    test_indices = shuffled_indices[train_size:]\n",
    "    train_set = [data[i] for i in train_indices]\n",
    "    test_set = [data[i] for i in test_indices]\n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the train and test data sets\n",
    "movies = fetch_movies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Movie length\n",
    "movie_lengths = [movie['place'].shape[0] for movie in movies]\n",
    "print(\"Max movie length: {}\".format(max(movie_lengths)))\n",
    "print(\"Min movie length: {}\".format(min(movie_lengths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_DIM = 2048 + 512 + 512 + 512\n",
    "MAX_MOVIE_LENGTH = 4000\n",
    "NUM_EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split movies into training and validation sets\n",
    "# movies_train, movies_val = split_train_test(movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def transform_movies(movies, features=['place', 'cast', 'action', 'audio'], pad_len=MAX_MOVIE_LENGTH):\n",
    "    \"\"\"\n",
    "    Unroll the given features by column and separate features from labels.\n",
    "    Then pad the sequences in each movie to the length of the longest movie.\n",
    "    \n",
    "    Arguments:\n",
    "    ----------\n",
    "    movies -- a list of dictionaries each containing a movie information\n",
    "    features -- list of string representing data features\n",
    "    pad-len -- integer for the maximum length of a movie\n",
    "    \n",
    "    Return:\n",
    "    -------\n",
    "    X_padded -- a 2D numpy array\n",
    "    Y_padded -- a 2D numpy array\n",
    "    \"\"\"\n",
    "    X, Y = [], []\n",
    "    # Unroll the features\n",
    "    for movie in movies: \n",
    "        row = torch.cat([movie[feat] for feat in features], dim=1)\n",
    "        X.append(row.numpy())\n",
    "        # Pre-pad the label since its length is N-1\n",
    "        labels = movie['scene_transition_boundary_ground_truth']\n",
    "        labels = torch.cat([torch.tensor([False]), labels])\n",
    "        Y.append(labels.numpy())\n",
    "    # Pad the sequences\n",
    "    X_padded = pad_sequences(X, maxlen=pad_len, padding='post', dtype='float32')\n",
    "    Y_padded = pad_sequences(Y, value=False, maxlen=pad_len, padding='post')\n",
    "    return X_padded, Y_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Transform training and validation sets\n",
    "# X_train, y_train = transform_movies(movies_train)\n",
    "# X_val, y_val = transform_movies(movies_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build and train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    \"\"\"To stop training early once accuracy reach 95%\"\"\"\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy') > 0.95):\n",
    "            print(\"\\nReached 95% accuracy, so cancelling training!\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpad_predictions(movies, yhat_probs):\n",
    "    \"\"\"\n",
    "    Truncate the padded predictions to movie's original length\n",
    "    \n",
    "    Arguments:\n",
    "    ----------\n",
    "    movies -- a list of dictionaries containing movies information\n",
    "    yhat_probs -- a 2D numpy array representing prediction for the given movies data set\n",
    "    \n",
    "    Return:\n",
    "    -------\n",
    "    yhat_dict -- a dictionary with each movie imbd_id as key and \n",
    "                 prediction probabilities as a 1D numpy array\n",
    "    \"\"\"\n",
    "    imdb_lengths = [(movie['imdb_id'], movie['place'].shape[0]) for movie in movies]\n",
    "    yhat_dict = dict()\n",
    "    for (imdb, length), yhat in zip(imdb_lengths, yhat_probs):\n",
    "        yhat = yhat[1:length]\n",
    "        yhat_dict[imdb] = yhat\n",
    "    return yhat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_predictions(yhat_unpadded_dict, path=PATH):\n",
    "    \"\"\"\n",
    "    Pickle the predictions\n",
    "    \n",
    "    Arguments:\n",
    "    ----------\n",
    "    yhat_unpadded_dict -- a dictionary of prediction consistent with the length of the ground-truth label\n",
    "    path -- a string representing the files path\n",
    "    \"\"\"\n",
    "    for imdb in yhat_unpadded_dict.keys():\n",
    "        # Load existing pkl movie file\n",
    "        filename = os.path.join(PATH, imdb + \".pkl\")\n",
    "        try:\n",
    "            x = pickle.load(open(filename, \"rb\"))\n",
    "            x['scene_transition_boundary_prediction'] = yhat_unpadded_dict[imdb].flatten()\n",
    "            pickle.dump(x, open(filename, \"wb\"))\n",
    "        except:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, transform the entire dataset \n",
    "X, y = transform_movies(movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_lstm(n_neurons=32, input_shape=[FEATURES_DIM]):\n",
    "#     model = tf.keras.Sequential([\n",
    "#             tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=n_neurons,\n",
    "#                                                                input_shape=input_shape,\n",
    "#                                                                return_sequences=True)),\n",
    "#             tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(1, activation='sigmoid'))])\n",
    "#     model.compile(loss='binary_crossentropy',\n",
    "#               optimizer=tf.keras.optimizers.RMSprop(lr=2e-5),\n",
    "#               metrics=['accuracy'])\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit classifier\n",
    "# lstm_clf = build_lstm()\n",
    "# lstm_clf.fit(X, y, epochs=NUM_EPOCHS, callbacks=[myCallback()], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Predict\n",
    "# lstm_yhat = lstm_clf.predict(X)\n",
    "# lstm_yhat_unpadded = unpad_predictions(movies, lstm_yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pickle predictions\n",
    "# write_predictions(lstm_yhat_unpadded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 WaveNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_wave_net(input_shape=[None, FEATURES_DIM], num_blocks=2, num_layers=3, \n",
    "                   filters1=20, filters2=10, kern1=2, kern2=1, padding='same'):\n",
    "    rates = [2**i for i in range(num_layers)]\n",
    "    wave_model = tf.keras.models.Sequential()\n",
    "    wave_model.add(tf.keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for rate in rates * num_blocks:\n",
    "        wave_model.add(tf.keras.layers.Conv1D(filters=filters1, \n",
    "                                              kernel_size=kern1, \n",
    "                                              padding='same',\n",
    "                                              activation='relu', dilation_rate=rate))\n",
    "    wave_model.add(tf.keras.layers.Conv1D(filters=filters2, kernel_size=kern2))\n",
    "    wave_model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    wave_model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=tf.keras.optimizers.RMSprop(lr=2e-5),\n",
    "                  metrics=['accuracy'])\n",
    "    return wave_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_clf = build_wave_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2/2 - 46s - loss: 0.6757 - accuracy: 0.8971\n",
      "Epoch 2/5\n",
      "2/2 - 39s - loss: 0.6616 - accuracy: 0.9399\n",
      "Epoch 3/5\n",
      "2/2 - 55s - loss: 0.6483 - accuracy: 0.9569\n",
      "Epoch 4/5\n",
      "2/2 - 23s - loss: 0.6362 - accuracy: 0.9638\n",
      "Epoch 5/5\n",
      "2/2 - 18s - loss: 0.6258 - accuracy: 0.9665\n",
      "CPU times: user 2min 39s, sys: 1min 43s, total: 4min 23s\n",
      "Wall time: 3min 2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd9e7ac7070>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "wave_clf.fit(X, y, epochs=5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_hat = wave_clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_hat_unpadded = unpad_predictions(movies, wave_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_predictions(wave_hat_unpadded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "keras_clf = KerasClassifier(build_wave_net)\n",
    "\n",
    "params_distribs = {\n",
    "    \"num_blocks\": [2, 3],\n",
    "    \"num_layers\": np.arange(4, 11),\n",
    "    \"filters1\": np.arange(10, 21),\n",
    "    \"filters2\": np.arange(2, 11)\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_clf, params_distribs, n_iter=5, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 46s 3s/step - loss: 0.6931 - accuracy: 0.4878\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 17s 3s/step - loss: 0.6927 - accuracy: 0.9701\n",
      "\n",
      "Reached 95% accuracy, so cancelling training!\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.6925 - accuracy: 0.9652\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 69s 5s/step - loss: 0.6932 - accuracy: 0.6314\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 26s 3s/step - loss: 0.6926 - accuracy: 0.9645\n",
      "\n",
      "Reached 95% accuracy, so cancelling training!\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.6923 - accuracy: 0.9705\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 50s 4s/step - loss: 0.6930 - accuracy: 0.9333\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 29s 6s/step - loss: 0.6923 - accuracy: 0.9676\n",
      "\n",
      "Reached 95% accuracy, so cancelling training!\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.6919 - accuracy: 0.9694\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 54s 4s/step - loss: 0.6934 - accuracy: 0.4401\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 19s 4s/step - loss: 0.6928 - accuracy: 0.8963\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 20s 5s/step - loss: 0.6924 - accuracy: 0.9703\n",
      "\n",
      "Reached 95% accuracy, so cancelling training!\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.6922 - accuracy: 0.9652\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 48s 4s/step - loss: 0.6931 - accuracy: 0.6952\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 20s 4s/step - loss: 0.6928 - accuracy: 0.9618\n",
      "\n",
      "Reached 95% accuracy, so cancelling training!\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd88ece1790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 15s 15s/step - loss: 0.6926 - accuracy: 0.9697\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 39s 5s/step - loss: 0.6930 - accuracy: 0.8627\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 20s 7s/step - loss: 0.6926 - accuracy: 0.9586\n",
      "\n",
      "Reached 95% accuracy, so cancelling training!\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9e0deadc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 11s 11s/step - loss: 0.6923 - accuracy: 0.9687\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 48s 6s/step - loss: 0.6932 - accuracy: 0.5004\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 21s 5s/step - loss: 0.6927 - accuracy: 0.9688\n",
      "\n",
      "Reached 95% accuracy, so cancelling training!\n",
      "WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd96ef97790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.6924 - accuracy: 0.9652\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 41s 5s/step - loss: 0.6928 - accuracy: 0.9475\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 19s 6s/step - loss: 0.6921 - accuracy: 0.9672\n",
      "\n",
      "Reached 95% accuracy, so cancelling training!\n",
      "WARNING:tensorflow:8 out of the last 8 calls to <function Model.make_test_function.<locals>.test_function at 0x7fdd89e26820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 14s 14s/step - loss: 0.6915 - accuracy: 0.9705\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 55s 6s/step - loss: 0.6931 - accuracy: 0.6220\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 30s 11s/step - loss: 0.6927 - accuracy: 0.9684\n",
      "\n",
      "Reached 95% accuracy, so cancelling training!\n",
      "WARNING:tensorflow:9 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd88ece1430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 14s 14s/step - loss: 0.6923 - accuracy: 0.9694\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 57s 6s/step - loss: 0.6937 - accuracy: 0.5857\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 24s 7s/step - loss: 0.6930 - accuracy: 0.6673\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 27s 5s/step - loss: 0.6925 - accuracy: 0.9131\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 23s 4s/step - loss: 0.6922 - accuracy: 0.9675\n",
      "\n",
      "Reached 95% accuracy, so cancelling training!\n",
      "WARNING:tensorflow:10 out of the last 10 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd892de8820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 10s 10s/step - loss: 0.6919 - accuracy: 0.9652\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 49s 9s/step - loss: 0.6930 - accuracy: 0.9667\n",
      "\n",
      "Reached 95% accuracy, so cancelling training!\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd892de2a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 11s 11s/step - loss: 0.6922 - accuracy: 0.9705\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 59s 6s/step - loss: 0.6934 - accuracy: 0.5712\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 25s 6s/step - loss: 0.6927 - accuracy: 0.9618\n",
      "\n",
      "Reached 95% accuracy, so cancelling training!\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd96ef975e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 14s 14s/step - loss: 0.6923 - accuracy: 0.9694\n",
      "Epoch 1/50\n",
      "2/2 [==============================] - 45s 5s/step - loss: 0.6896 - accuracy: 0.9693\n",
      "\n",
      "Reached 95% accuracy, so cancelling training!\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9ea2a7f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 10s 10s/step - loss: 0.6884 - accuracy: 0.9651\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:5 out of the last 17 calls to <function Model.make_train_function.<locals>.train_function at 0x7fdd899925e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 48s 6s/step - loss: 0.6914 - accuracy: 0.9519\n",
      "\n",
      "Reached 95% accuracy, so cancelling training!\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd88ece13a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.6896 - accuracy: 0.9616\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7fd892de2550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 50s 6s/step - loss: 0.6919 - accuracy: 0.9622\n",
      "\n",
      "Reached 95% accuracy, so cancelling training!\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd892de2310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 10s 10s/step - loss: 0.6911 - accuracy: 0.9665\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_train_function.<locals>.train_function at 0x7fd9dc2320d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 72s 10s/step - loss: 0.6944 - accuracy: 0.6670\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 24s 9s/step - loss: 0.6937 - accuracy: 0.6934\n",
      "Epoch 3/50\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rnd_search_cv.fit(X, y, epochs=NUM_EPOCHS, callbacks=[myCallback()])\n",
    "print(\"Best score: {}\".format(rnd_search.best_score_))\n",
    "print(\"Parameters:\")\n",
    "for param, value in rnd_search_cv.best_params_.items():\n",
    "    print(\"\\t{}: {}\".format(param, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection and performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
