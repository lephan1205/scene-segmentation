{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Scenes are important part of storytelling in movies. Detecting semantic scene changes involve understanding the interactions between actors and their environments. The task for this project is to build a machine learning system that detect semantic changes in movie scenes. First, let us define a few vocabularies. A movie is a sequence of _shots_ and _scenes_ and they are quite different. A __shot__ is series of frames captured by a camera for an uninterrupted period of time. A __scene__ is a plot-based semantic unit that is made up of a series of shots.\n",
    "\n",
    "The data is a set of 64 `<imbd id>.pkl` files provided by [eluv.io](https://eluv.io). Each file is a movie containing the following information:\n",
    "* Movie-level: the movie's IMBD identification.\n",
    "* Shot-level: four features (`place`, `cast`, `action`, and `audio`). These features are two-dimensional tensors extracted according to the encoding methods found in [(Rao et al.)](https://arxiv.org/pdf/2004.02678.pdf). The first dimension is the number of shots in the movie. The second dimension are 2048, 512, 512, 512, respectively.\n",
    "* Scene-level:\n",
    "    - Ground truth (`scene_transition_boundary_ground_truth`) which is a boolean vector labeling scene transition boundaries.\n",
    "    - Preliminary scene transition prediction (`scene_transition_boundary_prediction`) is a prediction template indicating the probability of a shot being a scene boundary.\n",
    "    - The `shot_end_frame` is used for evaluation purpose.\n",
    "    \n",
    "Now that we have the data related details out of the way, let us discuss the structure of the rest of this notebook. Section [1](#section1) and [2](#section2) are the typically setup to load the data. Section [3](#section3) go over the data processing and transformations. Section [4](#section4) builds and train LSTM and WaveNet models. Section [5](#section5') discusses hyperparameter tunning and Section [6](#section6) discusses model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section1'></a>\n",
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import torch\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "# Where to get the data\n",
    "PATH = os.path.join(os.getcwd(), \"data_dir\")\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2'></a>\n",
    "# 2. Get the data\n",
    "\n",
    "To load the data, we'll use the `fetch_movies()` function below to unpickle the files and load them into a list of Python dictionaries. Notice the length of the movies ranges from 600 shots to 3100 shots. We will use the maximum length later in the data transformation process so each training instance would have the same shape when fed into tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_movies(path=PATH):\n",
    "    \"\"\"\n",
    "    Load .pkl movie files\n",
    "    \n",
    "    Argument:\n",
    "    ---------\n",
    "    path -- string representing files path\n",
    "    \"\"\"\n",
    "    filenames = glob.glob(os.path.join(PATH, \"tt*.pkl\"))\n",
    "    movies = []\n",
    "    for fn in filenames:\n",
    "        try:\n",
    "            with open(fn, 'rb') as fin:\n",
    "                movies.append(pickle.load(fin))\n",
    "        except EOFError:\n",
    "            break\n",
    "    return movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = fetch_movies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the train and test data sets\n",
    "movies = fetch_movies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max movie length: 3096\n",
      "Min movie length: 607\n"
     ]
    }
   ],
   "source": [
    "# Movie length\n",
    "movie_lengths = [movie['place'].shape[0] for movie in movies]\n",
    "print(\"Max movie length: {}\".format(max(movie_lengths)))\n",
    "print(\"Min movie length: {}\".format(min(movie_lengths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_DIM = 2048 + 512 + 512 + 512\n",
    "MAX_MOVIE_LENGTH = 3100\n",
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section3'></a>\n",
    "# 3. Data processing\n",
    "\n",
    "Now that we got the data, we will build two custom functions, `split_train_test()` and `transform_movies()` to split the data set into training set and validation set as well as transform them from `torch.Tensor` to numpy arrays. The movies are padded in the transformation process with the `MAX_MOVIE_LENGTH` constant as noted earlier so they all have the same shape. We then call these functions to split and transform the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(data, train_size=52):\n",
    "    \"\"\"\n",
    "    Split data into train and test sets\n",
    "    \n",
    "    Argument:\n",
    "    --------\n",
    "    data -- a list of dictionaries each containing a movie information\n",
    "    train_size -- integer representing the number of movies used for training\n",
    "    \"\"\"\n",
    "    # For stable output across runs\n",
    "    np.random.seed(42)\n",
    "    # Shuffle indices\n",
    "    shuffled_indices = np.random.permutation(len(data))\n",
    "    train_indices = shuffled_indices[:train_size]\n",
    "    test_indices = shuffled_indices[train_size:]\n",
    "    train_set = [data[i] for i in train_indices]\n",
    "    test_set = [data[i] for i in test_indices]\n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def transform_movies(movies, features=['place', 'cast', 'action', 'audio'], pad_len=MAX_MOVIE_LENGTH):\n",
    "    \"\"\"\n",
    "    Unroll the given features by column and separate features from labels.\n",
    "    Then pad the sequences in each movie to the length of the longest movie.\n",
    "    \n",
    "    Arguments:\n",
    "    ----------\n",
    "    movies -- a list of dictionaries each containing a movie information\n",
    "    features -- list of string representing data features\n",
    "    pad-len -- integer for the maximum length of a movie\n",
    "    \n",
    "    Return:\n",
    "    -------\n",
    "    X_padded -- a 2D numpy array\n",
    "    Y_padded -- a 2D numpy array\n",
    "    \"\"\"\n",
    "    X, Y = [], []\n",
    "    # Unroll the features\n",
    "    for movie in movies: \n",
    "        row = torch.cat([movie[feat] for feat in features], dim=1)\n",
    "        X.append(row.numpy())\n",
    "        # Pre-pad the label since its length is N-1\n",
    "        labels = movie['scene_transition_boundary_ground_truth']\n",
    "        labels = torch.cat([torch.tensor([False]), labels])\n",
    "        Y.append(labels.numpy())\n",
    "    # Pad the sequences\n",
    "    X_padded = pad_sequences(X, maxlen=pad_len, padding='post', dtype='float32')\n",
    "    Y_padded = pad_sequences(Y, value=False, maxlen=pad_len, padding='post')\n",
    "    return X_padded, Y_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split movies into training and validation sets\n",
    "movies_train, movies_val = split_train_test(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform training and validation sets\n",
    "X_train, y_train = transform_movies(movies_train)\n",
    "X_val, y_val = transform_movies(movies_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section4'></a>\n",
    "# 4. Train LSTM and WaveNet\n",
    "\n",
    "Since the training instances are sequences of shots, the logical models would be that of a recurrent neural network (RNN) architecture. However, simpple RNNs do not work well with long sequences. At each time step, the RNN only take the current input and an activation value from the previous time step to make prediction for the current time step. This means a RNN cannot learn from sequences that have long-term dependencies. In particular, if the network is very deep, then the gradient from the output will have a hard time propagating back to affect the earlier layers. That is, as the data traverses the RNN it goes through a series of transformations and after a while, there is very little trace of the first inputs.\n",
    "\n",
    "To combat this problem, we can use __Long Short-Term Memory (LSTM)__ cell which is better at detecting long-term dependencies in the data. It uses update and forget gates that allow the cell to keep more information from the earlier time step compared to RNN. LSTM training is also faster than RNN.\n",
    "\n",
    "Another method to deal with long sequences is the __WaveNet__ architecture introduced in a [2016 paper](https://arxiv.org/abs/1609.03499) by researchers at DeepMind. WaveNet stacks a group of 1D convolutional layers while doubling the dilation rate at every layer. Dilation rate means how far apart each neuron's inputs are. The first layer sees two time steps at a time while the next see four time steps, and so on. In essence, the lower layers in the stack learn short-term patterns while the higher layers learn long-term patterns. This network is extremely fast -- even for long sequences.\n",
    "\n",
    "Before building LSTM and WaveNet, we will build a customized `callback` class which we will pass as argument to the model's `fit()` method. This will allow the training to stop early when accuracy reaches 95%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    \"\"\"To stop training early once accuracy reach 95%\"\"\"\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy') > 0.95):\n",
    "            print(\"\\nReached 95% accuracy, so cancelling training!\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm(n_layers=2, n_neurons=32, input_shape=[None, FEATURES_DIM]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for _ in range(n_layers):\n",
    "        model.add(keras.layers.Bidirectional(keras.layers.LSTM(units=n_neurons,\n",
    "                                                               return_sequences=True)))\n",
    "    model.add(keras.layers.TimeDistributed(keras.layers.Dense(1, activation='sigmoid')))\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "              optimizer=keras.optimizers.RMSprop(lr=2e-5),\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 - 114s - loss: 0.6902 - accuracy: 0.7342 - val_loss: 0.6413 - val_accuracy: 0.9056\n",
      "Epoch 2/10\n",
      "2/2 - 87s - loss: 0.6212 - accuracy: 0.9342 - val_loss: 0.6034 - val_accuracy: 0.9414\n",
      "Epoch 3/10\n",
      "2/2 - 79s - loss: 0.5845 - accuracy: 0.9573 - val_loss: 0.5780 - val_accuracy: 0.9474\n",
      "\n",
      "Reached 95% accuracy, so cancelling training!\n",
      "CPU times: user 5min 50s, sys: 3min 7s, total: 8min 58s\n",
      "Wall time: 4min 42s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb7b86ec400>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Fit LSTM classifier\n",
    "lstm_clf = build_lstm()\n",
    "lstm_clf.fit(X_train, y_train, \n",
    "             epochs=NUM_EPOCHS, \n",
    "             callbacks=[myCallback()], \n",
    "             validation_data=(X_val, y_val), verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 WaveNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_wave_net(input_shape=[None, FEATURES_DIM], num_blocks=2, num_layers=4, \n",
    "                   filters1=10, filters2=5, kern1=2, kern2=1, padding='same'):\n",
    "    rates = [2**i for i in range(num_layers)]\n",
    "    wave_model = keras.models.Sequential()\n",
    "    wave_model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for rate in rates * num_blocks:\n",
    "        wave_model.add(keras.layers.Conv1D(filters=filters1, \n",
    "                                              kernel_size=kern1, \n",
    "                                              padding='same',\n",
    "                                              activation='relu', dilation_rate=rate))\n",
    "    wave_model.add(keras.layers.Conv1D(filters=filters2, kernel_size=kern2))\n",
    "    wave_model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "    wave_model.compile(loss='binary_crossentropy',\n",
    "                       optimizer=keras.optimizers.RMSprop(lr=2e-5),\n",
    "                       metrics=['accuracy'])\n",
    "    return wave_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 - 22s - loss: 0.6757 - accuracy: 0.9471 - val_loss: 0.6701 - val_accuracy: 0.9437\n",
      "Epoch 2/10\n",
      "2/2 - 13s - loss: 0.6669 - accuracy: 0.9570 - val_loss: 0.6629 - val_accuracy: 0.9461\n",
      "\n",
      "Reached 95% accuracy, so cancelling training!\n",
      "CPU times: user 44.4 s, sys: 28.6 s, total: 1min 13s\n",
      "Wall time: 36.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb2db4f8670>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Fit WaveNet classifier\n",
    "wave_clf = build_wave_net()\n",
    "wave_clf.fit(X_train, y_train, \n",
    "             epochs=NUM_EPOCHS, \n",
    "             callbacks=[myCallback()], \n",
    "             validation_data=(X_val, y_val), verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section5'></a>\n",
    "# 5. Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, the WaveNet architecture while deeper than the simple LSTM, it runs faster. Thus, we will be focusing on tunining the hyperparameter for WaveNet and use it as the final model. We'll take advantage of the `KerasClassifier` wrapper that allows us to use Scikit-Learn's functions with the WaveNet. Additionally, we will tune the hyperparameters using `RandomizedSearchCV` which randomly sample a smaller subset of the hyperparameter space. This is faster than `GridSearchCV` where search is conducted on a larger hyperparameter space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 LSTM tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "lstm_keras_clf = KerasClassifier(build_lstm)\n",
    "\n",
    "lstm_params_distribs = {\n",
    "    \"n_layers\": np.arange(1, 11),\n",
    "    \"n_neurons\": [2, 4, 8, 16, 32, 64]\n",
    "}\n",
    "\n",
    "lstm_rnd_search_cv = RandomizedSearchCV(lstm_keras_clf, lstm_params_distribs, n_iter=3, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 97s 24s/step - loss: 0.7009 - accuracy: 0.6142 - val_loss: 0.6943 - val_accuracy: 0.7093\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 63s 18s/step - loss: 0.6914 - accuracy: 0.7654 - val_loss: 0.6890 - val_accuracy: 0.8008\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 57s 16s/step - loss: 0.6858 - accuracy: 0.8496 - val_loss: 0.6849 - val_accuracy: 0.8667\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 52s 15s/step - loss: 0.6814 - accuracy: 0.8963 - val_loss: 0.6810 - val_accuracy: 0.9131\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 55s 16s/step - loss: 0.6775 - accuracy: 0.9267 - val_loss: 0.6770 - val_accuracy: 0.9331\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 57s 18s/step - loss: 0.6733 - accuracy: 0.9457 - val_loss: 0.6747 - val_accuracy: 0.9402\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 61s 19s/step - loss: 0.6710 - accuracy: 0.9521 - val_loss: 0.6720 - val_accuracy: 0.9440\n",
      "\n",
      "Reached 95% accuracy, so cancelling training!\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.6699 - accuracy: 0.9541\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 123s 31s/step - loss: 0.6079 - accuracy: 0.9420 - val_loss: 0.6084 - val_accuracy: 0.9451\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 97s 31s/step - loss: 0.6022 - accuracy: 0.9551 - val_loss: 0.6048 - val_accuracy: 0.9462\n",
      "\n",
      "Reached 95% accuracy, so cancelling training!\n",
      "1/1 [==============================] - 24s 24s/step - loss: 0.6063 - accuracy: 0.9618\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6919 - accuracy: 0.7857  WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb166c3ddc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 99s 31s/step - loss: 0.6919 - accuracy: 0.7865 - val_loss: 0.6911 - val_accuracy: 0.8327\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 76s 19s/step - loss: 0.6906 - accuracy: 0.8604 - val_loss: 0.6904 - val_accuracy: 0.8597\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 79s 23s/step - loss: 0.6900 - accuracy: 0.8876 - val_loss: 0.6898 - val_accuracy: 0.8806\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 72s 21s/step - loss: 0.6892 - accuracy: 0.9092 - val_loss: 0.6892 - val_accuracy: 0.8981\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 60s 16s/step - loss: 0.6886 - accuracy: 0.9284 - val_loss: 0.6887 - val_accuracy: 0.9099\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 61s 18s/step - loss: 0.6881 - accuracy: 0.9344 - val_loss: 0.6883 - val_accuracy: 0.9196\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 63s 19s/step - loss: 0.6878 - accuracy: 0.9399 - val_loss: 0.6880 - val_accuracy: 0.9250\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 63s 18s/step - loss: 0.6875 - accuracy: 0.9445 - val_loss: 0.6877 - val_accuracy: 0.9311\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 56s 20s/step - loss: 0.6873 - accuracy: 0.9492 - val_loss: 0.6875 - val_accuracy: 0.9354\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 62s 19s/step - loss: 0.6870 - accuracy: 0.9516 - val_loss: 0.6872 - val_accuracy: 0.9392\n",
      "\n",
      "Reached 95% accuracy, so cancelling training!\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.6863 - accuracy: 0.9504\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 235s 64s/step - loss: 0.7020 - accuracy: 0.4574 - val_loss: 0.6969 - val_accuracy: 0.5677\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 124s 38s/step - loss: 0.6979 - accuracy: 0.5706 - val_loss: 0.6926 - val_accuracy: 0.7191\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 152s 54s/step - loss: 0.6937 - accuracy: 0.6873 - val_loss: 0.6895 - val_accuracy: 0.8241\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 136s 46s/step - loss: 0.6902 - accuracy: 0.7984 - val_loss: 0.6867 - val_accuracy: 0.8974\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 134s 46s/step - loss: 0.6872 - accuracy: 0.8837 - val_loss: 0.6849 - val_accuracy: 0.9230\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 114s 37s/step - loss: 0.6853 - accuracy: 0.9144 - val_loss: 0.6838 - val_accuracy: 0.9346\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 119s 36s/step - loss: 0.6839 - accuracy: 0.9328 - val_loss: 0.6827 - val_accuracy: 0.9422\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 120s 36s/step - loss: 0.6827 - accuracy: 0.9463 - val_loss: 0.6816 - val_accuracy: 0.9457\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 91s 32s/step - loss: 0.6815 - accuracy: 0.9537 - val_loss: 0.6808 - val_accuracy: 0.9465\n",
      "\n",
      "Reached 95% accuracy, so cancelling training!\n",
      "1/1 [==============================] - 34s 34s/step - loss: 0.6813 - accuracy: 0.9471\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 224s 72s/step - loss: 0.6639 - accuracy: 0.9494 - val_loss: 0.6632 - val_accuracy: 0.9464\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 194s 56s/step - loss: 0.6602 - accuracy: 0.9558 - val_loss: 0.6609 - val_accuracy: 0.9470\n",
      "\n",
      "Reached 95% accuracy, so cancelling training!\n",
      "1/1 [==============================] - 35s 35s/step - loss: 0.6603 - accuracy: 0.9637\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6844 - accuracy: 0.8580  WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb03d6e6f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 258s 76s/step - loss: 0.6845 - accuracy: 0.8586 - val_loss: 0.6837 - val_accuracy: 0.8784\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 131s 45s/step - loss: 0.6816 - accuracy: 0.9186 - val_loss: 0.6819 - val_accuracy: 0.8988\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 114s 41s/step - loss: 0.6803 - accuracy: 0.9327 - val_loss: 0.6807 - val_accuracy: 0.9109\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 112s 45s/step - loss: 0.6792 - accuracy: 0.9410 - val_loss: 0.6796 - val_accuracy: 0.9230\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 97s 32s/step - loss: 0.6784 - accuracy: 0.9454 - val_loss: 0.6790 - val_accuracy: 0.9252\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 97s 38s/step - loss: 0.6778 - accuracy: 0.9480 - val_loss: 0.6783 - val_accuracy: 0.9288\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 92s 34s/step - loss: 0.6772 - accuracy: 0.9505 - val_loss: 0.6778 - val_accuracy: 0.9318\n",
      "\n",
      "Reached 95% accuracy, so cancelling training!\n",
      "1/1 [==============================] - 33s 33s/step - loss: 0.6752 - accuracy: 0.9584\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.7062 - accuracy: 0.5852  WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb04c9c1b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 163s 44s/step - loss: 0.7062 - accuracy: 0.5863 - val_loss: 0.7005 - val_accuracy: 0.6307\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 87s 25s/step - loss: 0.6963 - accuracy: 0.6758 - val_loss: 0.6909 - val_accuracy: 0.7202\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 82s 27s/step - loss: 0.6859 - accuracy: 0.7732 - val_loss: 0.6834 - val_accuracy: 0.7958\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 111s 37s/step - loss: 0.6791 - accuracy: 0.8401 - val_loss: 0.6789 - val_accuracy: 0.8398\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 132s 50s/step - loss: 0.6746 - accuracy: 0.8820 - val_loss: 0.6730 - val_accuracy: 0.8921\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 120s 39s/step - loss: 0.6699 - accuracy: 0.9153 - val_loss: 0.6703 - val_accuracy: 0.9107\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 106s 39s/step - loss: 0.6673 - accuracy: 0.9337 - val_loss: 0.6676 - val_accuracy: 0.9246\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 97s 28s/step - loss: 0.6652 - accuracy: 0.9452 - val_loss: 0.6663 - val_accuracy: 0.9304\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 90s 39s/step - loss: 0.6639 - accuracy: 0.9503 - val_loss: 0.6653 - val_accuracy: 0.9336\n",
      "\n",
      "Reached 95% accuracy, so cancelling training!\n",
      "1/1 [==============================] - 28s 28s/step - loss: 0.6631 - accuracy: 0.9467\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 224s 64s/step - loss: 0.6873 - accuracy: 0.9275 - val_loss: 0.6863 - val_accuracy: 0.9411\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 161s 39s/step - loss: 0.6861 - accuracy: 0.9481 - val_loss: 0.6858 - val_accuracy: 0.9437\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 122s 43s/step - loss: 0.6855 - accuracy: 0.9516 - val_loss: 0.6855 - val_accuracy: 0.9453\n",
      "\n",
      "Reached 95% accuracy, so cancelling training!\n",
      "1/1 [==============================] - 28s 28s/step - loss: 0.6857 - accuracy: 0.9586\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6857 - accuracy: 0.9620  WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb03bebdca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 167s 49s/step - loss: 0.6857 - accuracy: 0.9619 - val_loss: 0.6851 - val_accuracy: 0.9484\n",
      "\n",
      "Reached 95% accuracy, so cancelling training!\n",
      "WARNING:tensorflow:6 out of the last 16 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb03bebdca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 18s 18s/step - loss: 0.6841 - accuracy: 0.9606\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7fb15bf3d730>, as the constructor either does not set or modifies parameter n_layers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0;31m# we clone again after setting params in case some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;31m# of the params are estimators as well.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[0m\u001b[1;32m    762\u001b[0m                 **self.best_params_))\n\u001b[1;32m    763\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mparam2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparam1\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparam2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[0m\u001b[1;32m     97\u001b[0m                                \u001b[0;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                                (estimator, name))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7fb15bf3d730>, as the constructor either does not set or modifies parameter n_layers"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lstm_rnd_search_cv.fit(X_train, y_train, epochs=NUM_EPOCHS, \n",
    "                       validation_data=(X_val, y_val),\n",
    "                       callbacks=[myCallback()], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.9564256270726522\n",
      "Parameters:\n",
      "\tn_neurons: 2\n",
      "\tn_layers: 8\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score: {}\".format(lstm_rnd_search_cv.best_score_))\n",
    "print(\"Parameters:\")\n",
    "for param, value in lstm_rnd_search_cv.best_params_.items():\n",
    "    print(\"\\t{}: {}\".format(param, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 WaveNet tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "wave_keras_clf = KerasClassifier(build_wave_net)\n",
    "\n",
    "wave_params_distribs = {\n",
    "    \"num_blocks\": [2, 3],\n",
    "    \"num_layers\": np.arange(4, 11),\n",
    "    \"filters1\": np.arange(10, 21),\n",
    "    \"filters2\": np.arange(2, 11)\n",
    "}\n",
    "\n",
    "wave_rnd_search_cv = RandomizedSearchCV(wave_keras_clf, wave_params_distribs, n_iter=3, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6921 - accuracy: 0.8995 WARNING:tensorflow:7 out of the last 17 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb03d6c8550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 35s 7s/step - loss: 0.6920 - accuracy: 0.8995 - val_loss: 0.6913 - val_accuracy: 0.9097\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 19s 4s/step - loss: 0.6911 - accuracy: 0.9237 - val_loss: 0.6904 - val_accuracy: 0.9210\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 18s 2s/step - loss: 0.6902 - accuracy: 0.9349 - val_loss: 0.6895 - val_accuracy: 0.9305\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 11s 2s/step - loss: 0.6891 - accuracy: 0.9429 - val_loss: 0.6886 - val_accuracy: 0.9364\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 10s 2s/step - loss: 0.6882 - accuracy: 0.9488 - val_loss: 0.6877 - val_accuracy: 0.9403\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 12s 2s/step - loss: 0.6872 - accuracy: 0.9537 - val_loss: 0.6868 - val_accuracy: 0.9435\n",
      "\n",
      "Reached 95% accuracy, so cancelling training!\n",
      "WARNING:tensorflow:6 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb03d6c8550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.6864 - accuracy: 0.9537\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6914 - accuracy: 0.8643 WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb2b2fa7160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 31s 5s/step - loss: 0.6914 - accuracy: 0.8646 - val_loss: 0.6899 - val_accuracy: 0.9109\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 12s 2s/step - loss: 0.6894 - accuracy: 0.9202 - val_loss: 0.6883 - val_accuracy: 0.9273\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 11s 2s/step - loss: 0.6877 - accuracy: 0.9378 - val_loss: 0.6871 - val_accuracy: 0.9338\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 11s 2s/step - loss: 0.6863 - accuracy: 0.9461 - val_loss: 0.6856 - val_accuracy: 0.9372\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 11s 2s/step - loss: 0.6846 - accuracy: 0.9494 - val_loss: 0.6843 - val_accuracy: 0.9392\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 10s 2s/step - loss: 0.6831 - accuracy: 0.9507 - val_loss: 0.6829 - val_accuracy: 0.9400\n",
      "\n",
      "Reached 95% accuracy, so cancelling training!\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.6825 - accuracy: 0.9567\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6934 - accuracy: 0.7098 WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb2b2927f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 41s 8s/step - loss: 0.6934 - accuracy: 0.7091 - val_loss: 0.6927 - val_accuracy: 0.7672\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 18s 3s/step - loss: 0.6928 - accuracy: 0.7664 - val_loss: 0.6922 - val_accuracy: 0.8167\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 10s 2s/step - loss: 0.6922 - accuracy: 0.8160 - val_loss: 0.6915 - val_accuracy: 0.8604\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 12s 3s/step - loss: 0.6915 - accuracy: 0.8581 - val_loss: 0.6908 - val_accuracy: 0.8870\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 22s 5s/step - loss: 0.6908 - accuracy: 0.8907 - val_loss: 0.6901 - val_accuracy: 0.9065\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 15s 3s/step - loss: 0.6901 - accuracy: 0.9141 - val_loss: 0.6894 - val_accuracy: 0.9180\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 12s 2s/step - loss: 0.6894 - accuracy: 0.9278 - val_loss: 0.6887 - val_accuracy: 0.9256\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 11s 2s/step - loss: 0.6886 - accuracy: 0.9370 - val_loss: 0.6881 - val_accuracy: 0.9309\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 8s 2s/step - loss: 0.6879 - accuracy: 0.9426 - val_loss: 0.6874 - val_accuracy: 0.9352\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 10s 2s/step - loss: 0.6872 - accuracy: 0.9479 - val_loss: 0.6867 - val_accuracy: 0.9376\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.6860 - accuracy: 0.9507\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 38s 7s/step - loss: 0.6931 - accuracy: 0.5487 - val_loss: 0.6928 - val_accuracy: 0.9485\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 16s 3s/step - loss: 0.6928 - accuracy: 0.9624 - val_loss: 0.6925 - val_accuracy: 0.9485\n",
      "\n",
      "Reached 95% accuracy, so cancelling training!\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.6925 - accuracy: 0.9595\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.3071 WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb03e5f8ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 36s 8s/step - loss: 0.6932 - accuracy: 0.3167 - val_loss: 0.6927 - val_accuracy: 0.9485\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 12s 3s/step - loss: 0.6927 - accuracy: 0.9601 - val_loss: 0.6924 - val_accuracy: 0.9485\n",
      "\n",
      "Reached 95% accuracy, so cancelling training!\n",
      "WARNING:tensorflow:6 out of the last 17 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb03e5f8ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 9s 9s/step - loss: 0.6924 - accuracy: 0.9646\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.3439 WARNING:tensorflow:7 out of the last 18 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb040aa15e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 40s 6s/step - loss: 0.6931 - accuracy: 0.3529 - val_loss: 0.6929 - val_accuracy: 0.9485\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 12s 3s/step - loss: 0.6929 - accuracy: 0.9619 - val_loss: 0.6927 - val_accuracy: 0.9485\n",
      "\n",
      "Reached 95% accuracy, so cancelling training!\n",
      "WARNING:tensorflow:8 out of the last 20 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb040aa15e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.6927 - accuracy: 0.9607\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.6803 - accuracy: 0.8767 WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb03e583430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 24s 5s/step - loss: 0.6803 - accuracy: 0.8769 - val_loss: 0.6760 - val_accuracy: 0.8901\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 9s 1s/step - loss: 0.6750 - accuracy: 0.9008 - val_loss: 0.6719 - val_accuracy: 0.9030\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 7s 949ms/step - loss: 0.6708 - accuracy: 0.9143 - val_loss: 0.6678 - val_accuracy: 0.9143\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 7s 1s/step - loss: 0.6665 - accuracy: 0.9263 - val_loss: 0.6641 - val_accuracy: 0.9219\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 7s 1s/step - loss: 0.6622 - accuracy: 0.9346 - val_loss: 0.6614 - val_accuracy: 0.9257\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 7s 1s/step - loss: 0.6592 - accuracy: 0.9384 - val_loss: 0.6583 - val_accuracy: 0.9297\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 7s 972ms/step - loss: 0.6560 - accuracy: 0.9434 - val_loss: 0.6553 - val_accuracy: 0.9320\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 7s 1s/step - loss: 0.6529 - accuracy: 0.9474 - val_loss: 0.6521 - val_accuracy: 0.9351\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 5s 904ms/step - loss: 0.6491 - accuracy: 0.9507 - val_loss: 0.6495 - val_accuracy: 0.9367\n",
      "\n",
      "Reached 95% accuracy, so cancelling training!\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6474 - accuracy: 0.9458\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 25s 5s/step - loss: 0.7002 - accuracy: 0.5488 - val_loss: 0.6973 - val_accuracy: 0.6036\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 11s 2s/step - loss: 0.6979 - accuracy: 0.5825 - val_loss: 0.6963 - val_accuracy: 0.6257\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 8s 1s/step - loss: 0.6968 - accuracy: 0.6035 - val_loss: 0.6956 - val_accuracy: 0.6356\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 10s 2s/step - loss: 0.6960 - accuracy: 0.6182 - val_loss: 0.6951 - val_accuracy: 0.6468\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 9s 2s/step - loss: 0.6955 - accuracy: 0.6291 - val_loss: 0.6947 - val_accuracy: 0.6564\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 8s 1s/step - loss: 0.6950 - accuracy: 0.6460 - val_loss: 0.6943 - val_accuracy: 0.6678\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 8s 1s/step - loss: 0.6946 - accuracy: 0.6511 - val_loss: 0.6940 - val_accuracy: 0.6743\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 7s 1s/step - loss: 0.6942 - accuracy: 0.6593 - val_loss: 0.6937 - val_accuracy: 0.6830\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 5s 1s/step - loss: 0.6939 - accuracy: 0.6679 - val_loss: 0.6934 - val_accuracy: 0.6902\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 5s 1s/step - loss: 0.6936 - accuracy: 0.6765 - val_loss: 0.6932 - val_accuracy: 0.6959\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6932 - accuracy: 0.7090\n",
      "Epoch 1/10\n",
      "2/2 [==============================] - 33s 7s/step - loss: 0.6813 - accuracy: 0.9347 - val_loss: 0.6766 - val_accuracy: 0.9287\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 10s 2s/step - loss: 0.6762 - accuracy: 0.9413 - val_loss: 0.6728 - val_accuracy: 0.9325\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 7s 1s/step - loss: 0.6723 - accuracy: 0.9456 - val_loss: 0.6687 - val_accuracy: 0.9363\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 7s 1s/step - loss: 0.6682 - accuracy: 0.9495 - val_loss: 0.6645 - val_accuracy: 0.9392\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 7s 1s/step - loss: 0.6635 - accuracy: 0.9533 - val_loss: 0.6607 - val_accuracy: 0.9413\n",
      "\n",
      "Reached 95% accuracy, so cancelling training!\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.6547 - accuracy: 0.9536\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7fb03fec8fd0>, as the constructor either does not set or modifies parameter num_layers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0;31m# we clone again after setting params in case some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;31m# of the params are estimators as well.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[0m\u001b[1;32m    762\u001b[0m                 **self.best_params_))\n\u001b[1;32m    763\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mparam2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparam1\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparam2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[0m\u001b[1;32m     97\u001b[0m                                \u001b[0;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                                (estimator, name))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7fb03fec8fd0>, as the constructor either does not set or modifies parameter num_layers"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "wave_rnd_search_cv.fit(X_train, y_train, epochs=NUM_EPOCHS, \n",
    "                       validation_data=(X_val, y_val),\n",
    "                       callbacks=[myCallback()],\n",
    "                       verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.9616220394770304\n",
      "Parameters:\n",
      "\tnum_layers: 9\n",
      "\tnum_blocks: 3\n",
      "\tfilters2: 10\n",
      "\tfilters1: 13\n"
     ]
    }
   ],
   "source": [
    "print(\"Best score: {}\".format(wave_rnd_search_cv.best_score_))\n",
    "print(\"Parameters:\")\n",
    "for param, value in wave_rnd_search_cv.best_params_.items():\n",
    "    print(\"\\t{}: {}\".format(param, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a good sense of the best hyperparameters, let us build a model based on these parameters. First, we will transform the full dataset and fit the best model on this full dataset. Recall that we padded the dataset so that all instances have identical input shape even though the movies are of different length. We will now need to reverse that padding by truncating the predictions so that the predictions for each movie have the same length at the movie itself. Then to write the prediction out to file for evaluation, we will use the `write_predictions()` function.\n",
    "\n",
    "Note that the required model evaluation metrics by Eluv.io are the __Mean Average Precision(mAP)__ and the __Mean Maximum IoU (mean Miou)__. The evaluation script, `evaluate_sceneseg.py` can be found at the Eluv.io's team [Github page](https://github.com/eluv-io/elv-ml-challenge)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpad_predictions(movies, yhat_probs):\n",
    "    \"\"\"\n",
    "    Truncate the padded predictions to movie's original length\n",
    "    \n",
    "    Arguments:\n",
    "    ----------\n",
    "    movies -- a list of dictionaries containing movies information\n",
    "    yhat_probs -- a 2D numpy array representing prediction for the given movies data set\n",
    "    \n",
    "    Return:\n",
    "    -------\n",
    "    yhat_dict -- a dictionary with each movie imbd_id as key and \n",
    "                 prediction probabilities as a 1D numpy array\n",
    "    \"\"\"\n",
    "    imdb_lengths = [(movie['imdb_id'], movie['place'].shape[0]) for movie in movies]\n",
    "    yhat_dict = dict()\n",
    "    for (imdb, length), yhat in zip(imdb_lengths, yhat_probs):\n",
    "        yhat = yhat[1:length]\n",
    "        yhat_dict[imdb] = yhat\n",
    "    return yhat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_predictions(yhat_unpadded_dict, path=PATH):\n",
    "    \"\"\"\n",
    "    Pickle the predictions\n",
    "    \n",
    "    Arguments:\n",
    "    ----------\n",
    "    yhat_unpadded_dict -- a dictionary of prediction consistent with the length of the ground-truth label\n",
    "    path -- a string representing the files path\n",
    "    \"\"\"\n",
    "    for imdb in yhat_unpadded_dict.keys():\n",
    "        # Load existing pkl movie file\n",
    "        filename = os.path.join(PATH, imdb + \".pkl\")\n",
    "        try:\n",
    "            x = pickle.load(open(filename, \"rb\"))\n",
    "            x['scene_transition_boundary_prediction'] = yhat_unpadded_dict[imdb].flatten()\n",
    "            pickle.dump(x, open(filename, \"wb\"))\n",
    "        except:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, transform the entire dataset \n",
    "X, y = transform_movies(movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us rebuild the WaveNet using the best hyperparameters and fit it on the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 67s 10s/step - loss: 0.6930 - accuracy: 0.9581\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 20s 9s/step - loss: 0.6926 - accuracy: 0.9601\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 23s 13s/step - loss: 0.6922 - accuracy: 0.9599\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 45s 12s/step - loss: 0.6918 - accuracy: 0.9590\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 20s 9s/step - loss: 0.6915 - accuracy: 0.9588\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 18s 9s/step - loss: 0.6913 - accuracy: 0.9612\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 28s 18s/step - loss: 0.6910 - accuracy: 0.9589\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 24s 10s/step - loss: 0.6908 - accuracy: 0.9598\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 19s 10s/step - loss: 0.6905 - accuracy: 0.9586\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 22s 12s/step - loss: 0.6903 - accuracy: 0.9595\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 21s 10s/step - loss: 0.6900 - accuracy: 0.9598\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 21s 11s/step - loss: 0.6898 - accuracy: 0.9587\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 20s 11s/step - loss: 0.6896 - accuracy: 0.9586\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 21s 10s/step - loss: 0.6893 - accuracy: 0.9590\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 23s 10s/step - loss: 0.6891 - accuracy: 0.9601\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 30s 15s/step - loss: 0.6889 - accuracy: 0.9585\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 20s 10s/step - loss: 0.6886 - accuracy: 0.9585\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 21s 9s/step - loss: 0.6884 - accuracy: 0.9590\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 10s 5s/step - loss: 0.6882 - accuracy: 0.9593\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 9s 4s/step - loss: 0.6879 - accuracy: 0.9598\n",
      "CPU times: user 8min 19s, sys: 5min 20s, total: 13min 40s\n",
      "Wall time: 8min 14s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb0554c3f70>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "wave_clf_best = build_wave_net(num_layers=9, num_blocks=3, filters1=13, filters2=10)\n",
    "wave_clf_best.fit(X, y, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and pickle results\n",
    "yhat_wave = wave_clf_best.predict(X)\n",
    "yhat_wave_unpadded = unpad_predictions(movies, yhat_wave)\n",
    "write_predictions(yhat_wave_unpadded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section6'></a>\n",
    "# 6. Performance evaluation\n",
    "\n",
    "In term of execution speed, WaveNet is much faster than LSTM by order of magnitude -- especially during hyperparameters tunning. __LSTM is prohibitively slow compares to WaveNet!__ Thus, much of the performance evaluation in this section will focus on the WaveNet model.\n",
    "\n",
    "To tune the hyperparameters, a round of random search cross-validation was carried out using tensorflow's `RandomSearchCV` class. This was done using 3-fold cross validation, three iterations, and an early stop criteria of 95% accuracy. Base on the result of the random search, another round of manual tuning was conducted which result in Table 1 below. \n",
    "\n",
    "Let $N$ be the number of blocks in the WaveNet and $L$ be the number of dilation layers in the block, we can derive the following insights:\n",
    "\n",
    "* The number of filters used in the WaveNet does not materially impact performance metrics when $N > 3$ and $L > 4$.\n",
    "* $N$ and $L$ has greater impact on performance metrics than the number of filters.\n",
    "* Miou metric is almost unaffected by changes in hyperparameters.\n",
    "\n",
    "<img src='images/performance.png' width=700/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
