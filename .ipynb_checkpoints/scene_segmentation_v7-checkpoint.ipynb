{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Scenes are important part of storytelling in movies. Detecting semantic scene changes involve understanding the interactions between actors and their environments. The task for this project is to build a machine learning system that detect semantic changes in movie scenes. First, let us define a few vocabularies. A movie is a sequence of _shots_ and _scenes_ and they are quite different. A __shot__ is series of frames captured by a camera for an uninterrupted period of time. A __scene__ is a plot-based semantic unit that is made up of a series of shots.\n",
    "\n",
    "The data is a set of 64 `<imbd id>.pkl` files provided by [eluv.io](https://eluv.io). Each file is a movie containing the following information:\n",
    "* Movie-level: the movie's IMBD identification.\n",
    "* Shot-level: four features (`place`, `cast`, `action`, and `audio`). These features are two-dimensional tensors extracted according to the encoding methods found in [(Rao et al.)](https://arxiv.org/pdf/2004.02678.pdf). The first dimension is the number of shots in the movie. The second dimension are 2048, 512, 512, 512, respectively.\n",
    "* Scene-level:\n",
    "    - Ground truth (`scene_transition_boundary_ground_truth`) which is a boolean vector labeling scene transition boundaries.\n",
    "    - Preliminary scene transition prediction (`scene_transition_boundary_prediction`) is a prediction template indicating the probability of a shot being a scene boundary.\n",
    "    - The `shot_end_frame` is used for evaluation purpose.\n",
    "    \n",
    "Now that we have the data related details out of the way, let us discuss the structure of the rest of this notebook. Section [1](#section1) and [2](#section2) are the typically setup to load the data. Section [3](#section3) go over the data processing and transformations. Section [4](#section4) builds and train LSTM and WaveNet models. Section [5](#section5') discusses hyperparameter tunning and Section [6](#section6) discusses model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section1'></a>\n",
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import torch\n",
    "import glob\n",
    "import sys\n",
    "import os\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "# Where to get the data\n",
    "PATH = os.path.join(os.getcwd(), \"data_dir\")\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2'></a>\n",
    "## 2. Get the data\n",
    "\n",
    "To load the data, we'll use the `fetch_movies()` function below to unpickle the files and load them into a list of Python dictionaries. Notice the length of the movies ranges from 600 shots to 3100 shots. We will use the maximum length later in the data transformation process so each training instance would have the same shape when fed into tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_movies(path=PATH):\n",
    "    \"\"\"\n",
    "    Load .pkl movie files\n",
    "    \n",
    "    Argument:\n",
    "    ---------\n",
    "    path -- string representing files path\n",
    "    \"\"\"\n",
    "    filenames = glob.glob(os.path.join(PATH, \"tt*.pkl\"))\n",
    "    movies = []\n",
    "    for fn in filenames:\n",
    "        try:\n",
    "            with open(fn, 'rb') as fin:\n",
    "                movies.append(pickle.load(fin))\n",
    "        except EOFError:\n",
    "            break\n",
    "    return movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = fetch_movies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the train and test data sets\n",
    "movies = fetch_movies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max movie length: 3096\n",
      "Min movie length: 607\n"
     ]
    }
   ],
   "source": [
    "# Movie length\n",
    "movie_lengths = [movie['place'].shape[0] for movie in movies]\n",
    "print(\"Max movie length: {}\".format(max(movie_lengths)))\n",
    "print(\"Min movie length: {}\".format(min(movie_lengths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_DIM = 2048 + 512 + 512 + 512\n",
    "MAX_MOVIE_LENGTH = 3100\n",
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='section3'></a>\n",
    "## 3. Data processing\n",
    "\n",
    "Now that we got the data, we will build two custom functions, `split_train_test()` and `transform_movies()` to split the data set into training set and validation set as well as transform them from `torch.Tensor` to numpy arrays. The movies are padded in the transformation process with the `MAX_MOVIE_LENGTH` constant as noted earlier so they all have the same shape. We then call these functions to split and transform the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(data, train_size=52):\n",
    "    \"\"\"\n",
    "    Split data into train and test sets\n",
    "    \n",
    "    Argument:\n",
    "    --------\n",
    "    data -- a list of dictionaries each containing a movie information\n",
    "    train_size -- integer representing the number of movies used for training\n",
    "    \"\"\"\n",
    "    # For stable output across runs\n",
    "    np.random.seed(42)\n",
    "    # Shuffle indices\n",
    "    shuffled_indices = np.random.permutation(len(data))\n",
    "    train_indices = shuffled_indices[:train_size]\n",
    "    test_indices = shuffled_indices[train_size:]\n",
    "    train_set = [data[i] for i in train_indices]\n",
    "    test_set = [data[i] for i in test_indices]\n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def transform_movies(movies, features=['place', 'cast', 'action', 'audio'], pad_len=MAX_MOVIE_LENGTH):\n",
    "    \"\"\"\n",
    "    Unroll the given features by column and separate features from labels.\n",
    "    Then pad the sequences in each movie to the length of the longest movie.\n",
    "    \n",
    "    Arguments:\n",
    "    ----------\n",
    "    movies -- a list of dictionaries each containing a movie information\n",
    "    features -- list of string representing data features\n",
    "    pad-len -- integer for the maximum length of a movie\n",
    "    \n",
    "    Return:\n",
    "    -------\n",
    "    X_padded -- a 2D numpy array\n",
    "    Y_padded -- a 2D numpy array\n",
    "    \"\"\"\n",
    "    X, Y = [], []\n",
    "    # Unroll the features\n",
    "    for movie in movies: \n",
    "        row = torch.cat([movie[feat] for feat in features], dim=1)\n",
    "        X.append(row.numpy())\n",
    "        # Pre-pad the label since its length is N-1\n",
    "        labels = movie['scene_transition_boundary_ground_truth']\n",
    "        labels = torch.cat([torch.tensor([False]), labels])\n",
    "        Y.append(labels.numpy())\n",
    "    # Pad the sequences\n",
    "    X_padded = pad_sequences(X, maxlen=pad_len, padding='post', dtype='float32')\n",
    "    Y_padded = pad_sequences(Y, value=False, maxlen=pad_len, padding='post')\n",
    "    return X_padded, Y_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split movies into training and validation sets\n",
    "# movies_train, movies_val = split_train_test(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Transform training and validation sets\n",
    "# X_train, y_train = transform_movies(movies_train)\n",
    "# X_val, y_val = transform_movies(movies_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section4'></a>\n",
    "## 4. Train LSTM and WaveNet\n",
    "\n",
    "Since the training instances are sequences of shots, the logical models would be that of a recurrent neural network (RNN) architecture. However, simpple RNNs do not work well with long sequences. At each time step, the RNN only take the current input and an activation value from the previous time step to make prediction for the current time step. This means a RNN cannot learn from sequences that have long-term dependencies. In particular, if the network is very deep, then the gradient from the output will have a hard time propagating back to affect the earlier layers. That is, as the data traverses the RNN it goes through a series of transformations and after a while, there is very little trace of the first inputs.\n",
    "\n",
    "To combat this problem, we can use __Long Short-Term Memory (LSTM)__ cell which is better at detecting long-term dependencies in the data. It uses update and forget gates that allow the cell to keep more information from the earlier time step compared to RNN. LSTM training is also faster than RNN.\n",
    "\n",
    "Another method to deal with long sequences is the __WaveNet__ architecture introduced in a [2016 paper](https://arxiv.org/abs/1609.03499) by researchers at DeepMind. WaveNet stacks a group of 1D convolutional layers while doubling the dilation rate at every layer. Dilation rate means how far apart each neuron's inputs are. The first layer sees two time steps at a time while the next see four time steps, and so on. In essence, the lower layers in the stack learn short-term patterns while the higher layers learn long-term patterns. This network is extremely fast -- even for long sequences.\n",
    "\n",
    "Before building LSTM and WaveNet, we will build a customized `callback` class which we will pass as argument to the model's `fit()` method. This will allow the training to stop early when accuracy reaches 95%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    \"\"\"To stop training early once accuracy reach 95%\"\"\"\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy') > 0.95):\n",
    "            print(\"\\nReached 95% accuracy, so cancelling training!\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm(n_layers=2, n_neurons=32, input_shape=[None, FEATURES_DIM]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for _ in range(n_layers):\n",
    "        model.add(keras.layers.Bidirectional(keras.layers.LSTM(units=n_neurons,\n",
    "                                                               return_sequences=True)))\n",
    "    model.add(keras.layers.TimeDistributed(keras.layers.Dense(1, activation='sigmoid')))\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "              optimizer=keras.optimizers.RMSprop(lr=2e-5),\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Fit LSTM classifier\n",
    "# lstm_clf = build_lstm()\n",
    "# lstm_clf.fit(X_train, y_train, \n",
    "#              epochs=NUM_EPOCHS, \n",
    "#              callbacks=[myCallback()], \n",
    "#              validation_data=(X_val, y_val), verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 WaveNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_wave_net(input_shape=[None, FEATURES_DIM], num_blocks=2, num_layers=4, \n",
    "                   filters1=10, filters2=5, kern1=2, kern2=1, padding='same'):\n",
    "    rates = [2**i for i in range(num_layers)]\n",
    "    wave_model = keras.models.Sequential()\n",
    "    wave_model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for rate in rates * num_blocks:\n",
    "        wave_model.add(keras.layers.Conv1D(filters=filters1, \n",
    "                                              kernel_size=kern1, \n",
    "                                              padding='same',\n",
    "                                              activation='relu', dilation_rate=rate))\n",
    "    wave_model.add(keras.layers.Conv1D(filters=filters2, kernel_size=kern2))\n",
    "    wave_model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "    wave_model.compile(loss='binary_crossentropy',\n",
    "                       optimizer=keras.optimizers.RMSprop(lr=2e-5),\n",
    "                       metrics=['accuracy'])\n",
    "    return wave_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Fit WaveNet classifier\n",
    "# wave_clf = build_wave_net()\n",
    "# wave_clf.fit(X_train, y_train, \n",
    "#              epochs=NUM_EPOCHS, \n",
    "#              callbacks=[myCallback()], \n",
    "#              validation_data=(X_val, y_val), verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section5'></a>\n",
    "## 5. Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, the WaveNet architecture while deeper than the simple LSTM, it runs faster. Thus, we will be focusing on tunining the hyperparameter for WaveNet and use it as the final model. We'll take advantage of the `KerasClassifier` wrapper that allows us to use Scikit-Learn's functions with the WaveNet. Additionally, we will tune the hyperparameters using `RandomizedSearchCV` which randomly sample a smaller subset of the hyperparameter space. This is faster than `GridSearchCV` where search is conducted on a larger hyperparameter space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 LSTM tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# lstm_keras_clf = KerasClassifier(build_lstm)\n",
    "\n",
    "# lstm_params_distribs = {\n",
    "#     \"n_layers\": np.arange(1, 11),\n",
    "#     \"n_neurons\": [2, 4, 8, 16, 32, 64]\n",
    "# }\n",
    "\n",
    "# lstm_rnd_search_cv = RandomizedSearchCV(lstm_keras_clf, lstm_params_distribs, n_iter=3, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# lstm_rnd_search_cv.fit(X_train, y_train, epochs=NUM_EPOCHS, \n",
    "#                        validation_data=(X_val, y_val),\n",
    "#                        callbacks=[myCallback()], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Best score: {}\".format(lstm_rnd_search_cv.best_score_))\n",
    "# print(\"Parameters:\")\n",
    "# for param, value in lstm_rnd_search_cv.best_params_.items():\n",
    "#     print(\"\\t{}: {}\".format(param, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 WaveNet tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "wave_keras_clf = KerasClassifier(build_wave_net)\n",
    "\n",
    "wave_params_distribs = {\n",
    "    \"num_blocks\": [2, 3],\n",
    "    \"num_layers\": np.arange(4, 11),\n",
    "    \"filters1\": np.arange(10, 21),\n",
    "    \"filters2\": np.arange(2, 11)\n",
    "}\n",
    "\n",
    "wave_rnd_search_cv = RandomizedSearchCV(wave_keras_clf, wave_params_distribs, n_iter=3, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# wave_rnd_search_cv.fit(X_train, y_train, epochs=NUM_EPOCHS, \n",
    "#                        validation_data=(X_val, y_val),\n",
    "#                        callbacks=[myCallback()],\n",
    "#                        verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(\"Best score: {}\".format(wave_rnd_search_cv.best_score_))\n",
    "# print(\"Parameters:\")\n",
    "# for param, value in wave_rnd_search_cv.best_params_.items():\n",
    "#     print(\"\\t{}: {}\".format(param, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section6'></a>\n",
    "## 6. Model selection and performance\n",
    "\n",
    "Now that we have a good sense of the best hyperparameters, let us build a model based on these parameters. First, we will transform the full dataset and fit the best model on this full dataset. Recall that we padded the dataset so that all instances have identical input shape even though the movies are of different length. We will now need to reverse that padding by truncating the predictions so that the predictions for each movie have the same length at the movie itself. Then to write the prediction out to file for evaluation, we will use the `write_predictions()` function.\n",
    "\n",
    "Note that the required model evaluation metrics by Eluv.io are the __Mean Average Precision(mAP)__ and the __Mean Maximum IoU (mean Miou)__. The evaluation script, `evaluate_sceneseg.py` can be found at the Eluv.io's team [Github page](https://github.com/eluv-io/elv-ml-challenge)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpad_predictions(movies, yhat_probs):\n",
    "    \"\"\"\n",
    "    Truncate the padded predictions to movie's original length\n",
    "    \n",
    "    Arguments:\n",
    "    ----------\n",
    "    movies -- a list of dictionaries containing movies information\n",
    "    yhat_probs -- a 2D numpy array representing prediction for the given movies data set\n",
    "    \n",
    "    Return:\n",
    "    -------\n",
    "    yhat_dict -- a dictionary with each movie imbd_id as key and \n",
    "                 prediction probabilities as a 1D numpy array\n",
    "    \"\"\"\n",
    "    imdb_lengths = [(movie['imdb_id'], movie['place'].shape[0]) for movie in movies]\n",
    "    yhat_dict = dict()\n",
    "    for (imdb, length), yhat in zip(imdb_lengths, yhat_probs):\n",
    "        yhat = yhat[1:length]\n",
    "        yhat_dict[imdb] = yhat\n",
    "    return yhat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_predictions(yhat_unpadded_dict, path=PATH):\n",
    "    \"\"\"\n",
    "    Pickle the predictions\n",
    "    \n",
    "    Arguments:\n",
    "    ----------\n",
    "    yhat_unpadded_dict -- a dictionary of prediction consistent with the length of the ground-truth label\n",
    "    path -- a string representing the files path\n",
    "    \"\"\"\n",
    "    for imdb in yhat_unpadded_dict.keys():\n",
    "        # Load existing pkl movie file\n",
    "        filename = os.path.join(PATH, imdb + \".pkl\")\n",
    "        try:\n",
    "            x = pickle.load(open(filename, \"rb\"))\n",
    "            x['scene_transition_boundary_prediction'] = yhat_unpadded_dict[imdb].flatten()\n",
    "            pickle.dump(x, open(filename, \"wb\"))\n",
    "        except:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, transform the entire dataset \n",
    "X, y = transform_movies(movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us rebuild the WaveNet using the best hyperparameters and fit it on the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 - 56s - loss: 0.6952 - accuracy: 0.5535\n",
      "Epoch 2/10\n",
      "2/2 - 30s - loss: 0.6931 - accuracy: 0.6962\n",
      "Epoch 3/10\n",
      "2/2 - 34s - loss: 0.6921 - accuracy: 0.7874\n",
      "Epoch 4/10\n",
      "2/2 - 29s - loss: 0.6913 - accuracy: 0.8404\n",
      "Epoch 5/10\n",
      "2/2 - 29s - loss: 0.6905 - accuracy: 0.8719\n",
      "Epoch 6/10\n",
      "2/2 - 26s - loss: 0.6899 - accuracy: 0.8891\n",
      "Epoch 7/10\n",
      "2/2 - 38s - loss: 0.6892 - accuracy: 0.8996\n",
      "Epoch 8/10\n",
      "2/2 - 32s - loss: 0.6885 - accuracy: 0.9055\n",
      "Epoch 9/10\n",
      "2/2 - 19s - loss: 0.6877 - accuracy: 0.9094\n",
      "Epoch 10/10\n",
      "2/2 - 16s - loss: 0.6869 - accuracy: 0.9118\n",
      "CPU times: user 4min 43s, sys: 3min, total: 7min 44s\n",
      "Wall time: 5min 25s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcf071e24c0>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%time\n",
    "# wave_clf_best = build_wave_net(num_layers=8, num_blocks=2, filters1=20, filters2=10)\n",
    "# wave_clf_best.fit(X, y, epochs=NUM_EPOCHS, callbacks=[myCallback()], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fcf1cd72a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "# yhat_wave = wave_clf_best.predict(X)\n",
    "# yhat_wave_unpadded = unpad_predictions(movies, yhat_wave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_predictions(yhat_wave_unpadded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will rebuild the LSTM model with the best hyperparameters and fit it on the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lstm_clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lstm_clf' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lstm_clf_best = build_lstm(n_layers=8, n_neurons=4)\n",
    "lstm_clf_best.fit(X, y, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_lstm = lstm_clf_best.predict(X)\n",
    "yhat_lstm_unpadded = unpad_predictions(movies, yhat_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_predictions(yhat_lstm_unpadded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
